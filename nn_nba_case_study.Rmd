---
title: "Telco Case Study - NBA"
author: "Václav Čuřík"
date: "3/31/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=TRUE, warning=TRUE}
options(scipen = 999)

library(tidyverse)
library(skimr)
library(DataExplorer)

library(h2o)

```

```{r}
# Read sample data
data_tbl <- read_csv("sample.csv")
```

The dataset consists of 60,213 rows with 203 columns.

```{r}
data_tbl %>% skim()
```

There are quite a few columns with many missing values which we will need to address.

Column SubscriberID identifies the subscriber. But it is not unique, e.g. there is more than 1 row per subscriber.

```{r}
data_tbl %>% distinct(SubscriberID) # There are 50,331 unique customers in the dataset

data_tbl %>%
    mutate(SubscriberID = as.factor(SubscriberID)) %>% 
    count(SubscriberID) %>% 
    arrange(-n) %>% 
    count(n) 
```

Based on the SnapshotDate column, there are 3 different snaphot dates. 

```{r}
data_tbl %>% 
    count(SnapshotDate)
```

Looking at some subscribers with 2+ snapshots it seems there might be an issue with duplicated rows in the dataset. That is because there should not be more than 3 snapshots per subscriber and not all subscribers were present at all 3 snapshots.

We will check for duplicate rows, but first we need to remove the unnamed column with row id's, because it makes each row unique. And then we can remove columns which contain exactly the same values in all columns.

```{r}
deduplicated_data_tbl <- data_tbl %>% 
    select(-X1) %>% 
    distinct()
```

Now we are left with 58,536 unique rows for 50,331 unique subscribers. So the assumption is, there should be maximum 3 snapshots per subscriber.

```{r}
deduplicated_data_tbl %>%
    mutate(SubscriberID = as.factor(SubscriberID)) %>% 
    count(SubscriberID) %>% 
    arrange(-n) %>% 
    count(n) 
```

And that is not the case, there are still 8 subscribers with 4 snapshots.

```{r}
deduplicated_data_tbl %>%
    mutate(SubscriberID = as.factor(SubscriberID)) %>% 
    count(SubscriberID) %>% 
    filter(n == 4)
    
```

```{r}
deduplicated_data_tbl %>% 
    filter(SubscriberID == 975234957439)

deduplicated_data_tbl %>% 
    filter(SubscriberID == 6340676177439)

```

Looking at some examples of subscribers with 4 rows brings us to the binary campaign reaction outcomes (column campaign_1 to 16).

The only reason for given SubscriberID and SnaphostDate to occur more than once is a reaction to more than 1 campaign captured within the same snapshot.
The original assumption about max 3 rows per subscriber was wrong because the campaign response seems to be captured as a new observation within the same snapsshot.

For ML purposes we will not use either the SubscriberID or the SnapshotDate. Once these columns are removed we are safe to say that each row in our dataset contains a reaction to a specific campaign (if the value of one of the campaign reaction is 1 and there should be maximum of one reaction per row). Or if all campaign reaction columns are 0, then we know that no campaign attracted the subscriber.

```{r}
deduplicated_data_tbl %>%
    select(SubscriberID, SnapshotDate, campaign_1:campaign_16) %>% 
    mutate(campaign_total = select(., campaign_1:campaign_16) %>% rowSums(na.rm = TRUE)) %>% 
    select(SubscriberID, SnapshotDate, campaign_total, campaign_1:campaign_16) %>% 
    count(campaign_total)
```

```{r}
data_tbl %>% 
    select(SubscriberID, SnapshotDate, campaign_1:campaign_16) %>% 
    mutate(campaign_total = select(., campaign_1:campaign_16) %>% rowSums(na.rm = TRUE)) %>% 
    select(SubscriberID, SnapshotDate, campaign_total, campaign_1:campaign_16) %>% 
    count(campaign_total)
```


```{r}
deduplicated_data_tbl %>% 
    filter(SubscriberID == 166496509439) %>% 
    view()
```

```{r}
names <- apply(X = is.na(deduplicated_data_tbl), MARGIN = 2, FUN = mean) %>% names() %>% as_tibble() 

column_na_prop_tbl <- names %>% 
    bind_cols(
        apply(X = is.na(deduplicated_data_tbl), MARGIN = 2, FUN = mean) %>% as_tibble()        
    ) %>% rename(column = "value...1", na_prop = "value...2")

columns_to_remove <- column_na_prop_tbl %>% 
    filter(na_prop > 0.5) %>% 
    pull(1)
```

```{r}
selected_data_with_na_tbl <- deduplicated_data_tbl %>% 
    select(-all_of(columns_to_remove))
```

```{r}
selected_data_with_na_tbl %>% skim()
```


```{r}
selected_data_with_na_tbl %>% 
    slice(1:10) %>% 
    view()
```

```{r}
selected_data_with_na_tbl %>% names()
```


```{r}
count_na_func <- function(x) sum(is.na(x)) 

selected_data_na_count_tbl <- selected_data_with_na_tbl %>% 
    mutate(count_na = apply(., 1, count_na_func))

selected_data_na_count_tbl %>% 
    count(count_na) %>% 
    arrange(-count_na) %>% 
    view()

selected_data_na_count_tbl %>% 
    arrange(-count_na) %>% 
    slice(1:25) %>% 
    view()

```

```{r}
selected_data_na_count_tbl %>%
    mutate(campaign_total = select(., campaign_1:campaign_16) %>% rowSums(na.rm = TRUE)) %>% 
    filter(campaign_total > 0) %>% 
    select(SubscriberID, SnapshotDate, count_na, everything()) %>% 
    # count(count_na) %>% 
    # arrange(-count_na) %>% 
    #filter(count_na > 0) %>% 
    skim()

```

```{r}
selected_data_na_count_tbl %>%
    mutate(campaign_total = select(., campaign_1:campaign_16) %>% rowSums(na.rm = TRUE)) %>% 
    filter(campaign_total > 0) %>% 
    count(SalesChannel)
    filter(SalesChannel == "LMRA") %>% 
    select(starts_with("campaign"))
```

```{r}
columns_to_keep_data_tbl <- selected_data_na_count_tbl %>% 
    select(-c(starts_with("Customer"), SalesChannel, PackagePlanSubscriptionDate, SnapshotDate)) %>% 
    mutate(campaign_total = select(., campaign_1:campaign_16) %>% rowSums(na.rm = TRUE)) %>% 
    filter(campaign_total > 0) %>% 
    drop_na() %>%
    select(-SubscriberID, count_na)
```

```{r}
columns_to_keep_data_tbl %>% 
    count(campaign_total)
```

```{r}
prepared_data_tbl <- columns_to_keep_data_tbl %>% 
    filter(campaign_total == 1) %>% 
    select(-campaign_total)
```


```{r}
prepared_data_tbl$campaign <- names(prepared_data_tbl[1:16])[max.col(prepared_data_tbl[1:16], "last")]

prepared_data_tbl %>% view()
```

```{r}
prepared_data_tbl <- prepared_data_tbl %>% 
    select(campaign, everything(), -starts_with("campaign_"), -count_na)
```

```{r}
prepared_data_tbl %>% skim()
```

```{r}
prepared_data_tbl %>% 
    write_csv("training_data.csv")
```


# Multinomial Classification
```{r}
h2o.init()
```

```{r}
training_data <- h2o.importFile("training_data.csv") 
```

```{r}
y = "campaign"
x = setdiff(names(prepared_data_tbl), y)
```

```{r}
automl_h2o <- h2o.automl(
    x = x,
    y = y,
    training_frame = training_data,
    nfolds = 5,
    max_runtime_secs =  180
)
```

```{r}
automl_h2o
```

```{r}
automl_h2o %>% h2o.get_leaderboard()
```

```{r}
automl_h2o@leader
```

```{r}
automl_h2o@leader %>% 
    h2o.saveModel("models/")
```

```{r}
h2o.shutdown(prompt = FALSE)
```

# [test - does not work] PCA 

##  Training data - all 
```{r}
data_pca_tbl <- data_tbl %>% 
    select(-c(starts_with("campaign"), ...1, SubscriberID, SnapshotDate))

data_pca_tbl %>% 
    write_csv("data_pca_all.csv")

```


```{r}
h2o.init()
```

## Data for PCA
```{r}
pca_data_all <- h2o.importFile("data_pca_all.csv") 
```
## Train/Test split
```{r}
pca_data_split <- h2o.splitFrame(pca_data_all, ratios = 0.8, seed = 1234)
train <- pca_data_split[[1]]
test <- pca_data_split[[2]]
```


```{r}
pca_h2o <-h2o.prcomp(
    training_frame = train,
    k = 50,
    use_all_factor_levels = TRUE,
    pca_method = "GLRM",
    transform = "NONE",
    impute_missing = FALSE
    
) 
```


```{r}
pca_h2o
```


```{r}
pca_h2o@model$importance
```

```{r}
predictions_h2o <- h2o.predict(pca_h2o, newdata = test)
```
```{r}
predictions_h2o %>% 
    as_tibble()
```



```{r}
h2o.shutdown(prompt = FALSE)
```

